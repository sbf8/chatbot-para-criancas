import subprocess
import sys
import time
import random
import google.generativeai as genai
import os
import re
from google.genai.types import SafetySetting, HarmCategory, HarmBlockThreshold

def instalar_ou_atualizar_biblioteca(nome_biblioteca):
    """
    Instala ou atualiza uma biblioteca Python usando pip.

    Args:
        nome_biblioteca (str): O nome da biblioteca a ser instalada ou atualizada.
    """
    print(f"Instalando ou atualizando a biblioteca '{nome_biblioteca}'...")
    try:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', nome_biblioteca])
        print(f"Biblioteca '{nome_biblioteca}' instalada/atualizada com sucesso.")
    except subprocess.CalledProcessError as e:
        print(f"Erro ao instalar ou atualizar a biblioteca '{nome_biblioteca}': {e}")
        print(f"Por favor, verifique se vocÃª tem o pip instalado e configurado corretamente. Erro Detalhado: {e}")
        sys.exit(1)

def configurar_gemini_api():
    """
    Configura a API do Google Gemini.

    Returns:
        None
    Raises:
        ValueError: Se a chave da API nÃ£o for encontrada.
    """
    try:
        # Tenta obter a chave da API do Colab userdata ou da variÃ¡vel de ambiente
        chave_api = os.environ.get('GOOGLE_API_KEY')
        if not chave_api:
            try:
                from google.colab import userdata
                chave_api = userdata.get('GOOGLE_API_KEY')
            except ImportError:
                pass

        if not chave_api:
            raise ValueError("Chave da API do Google Gemini nÃ£o encontrada.")

        genai.configure(api_key=chave_api)
        print("API Key do Google Gemini carregada com sucesso!")
    except ValueError as e:
        print(f"Erro ao configurar a API do Google Gemini: {e}")
        print("Por favor, verifique se vocÃª configurou a chave da API do Google Gemini no Colab Secrets ou como variÃ¡vel de ambiente.")
        sys.exit(1)

def inicializar_modelo_chatbot():
    """
    Inicializa o modelo do Gemini com configuraÃ§Ãµes de seguranÃ§a.

    Returns:
        genai.GenerativeModel: O modelo do chatbot configurado.
    """
    modelo = "gemini-2.0-flash"
    configuracoes_seguranca = [
    {
        "category": HarmCategory.HARM_CATEGORY_HARASSMENT,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
]

    return genai.GenerativeModel(modelo, safety_settings=configuracoes_seguranca)

def obter_genero_do_nome(nome, modelo):
    """
    Determina o gÃªnero da crianÃ§a a partir do nome usando o modelo Gemini.

    Args:
        nome (str): O nome da crianÃ§a.
        modelo: O modelo do chatbot Gemini.

    Returns:
        str: 'masculino' ou 'feminino'.
    """
    prompt_genero = f"Qual o gÃªnero da crianÃ§a com o nome {nome}? Responda apenas 'masculino' ou 'feminino'."
    try:
        resposta_genero = modelo.start_chat().send_message(prompt_genero).text
        if "masculino" in resposta_genero.lower():
            return "masculino"
        elif "feminino" in resposta_genero.lower():
            return "feminino"
        else:
            return "aprendiz"  # Termo genÃ©rico caso o Gemini nÃ£o consiga determinar
    except Exception as e:
        print(f"Erro ao determinar o gÃªnero: {e}")
        return "aprendiz"  # Termo genÃ©rico em caso de erro

def gerar_resposta(pergunta, historico_conversa, informacoes_crianca, modelo_chat):
    """
    Gera uma resposta para a pergunta do usuÃ¡rio, utilizando o histÃ³rico da conversa e informaÃ§Ãµes da crianÃ§a.

    Args:
        pergunta (str): A pergunta do usuÃ¡rio.
        historico_conversa (list): O histÃ³rico da conversa atÃ© o momento.
        informacoes_crianca (dict): DicionÃ¡rio com nome, idade e cidade da crianÃ§a.
        modelo_chat: O modelo do chatbot Gemini.

    Returns:
        str: A resposta gerada pelo chatbot.
    """
    nome = informacoes_crianca.get("nome", "")
    idade = informacoes_crianca.get("idade", "")
    cidade = informacoes_crianca.get("cidade", "")
    termo_genero = informacoes_crianca.get("termo_genero", "aprendiz") # Novo campo para o termo de gÃªnero

    contexto_crianca = ""
    if nome:
        contexto_crianca += f"A crianÃ§a se chama {nome}. "
    if idade:
        contexto_crianca += f"Ela tem {idade} anos. "
    if cidade:
        contexto_crianca += f"Ela mora na cidade de {cidade}. "

    prompt_completo = f""" VocÃª Ã© o Amiguinho de Jesus, um chatbot especial,
    paciente e cheio de carinho, dedicado a ensinar crianÃ§as de 5 a 12 anos
    os valores e ensinamentos de O Evangelho Segundo o Espiritismo e O Livro
    dos EspÃ­ritos, codificados pelo Mestre Allan Kardec (Hippolyte LÃ©on
    Denizard Rivail). Sua missÃ£o Ã© pegar conceitos complexos â€” como caridade,
    amor ao prÃ³ximo, fÃ© raciocinada e comunicaÃ§Ã£o com o mundo espiritual â€” e
    transformÃ¡-los em histÃ³rias divertidas, metÃ¡foras simples e perguntas
    interativas que convidem a crianÃ§a a participar. Em cada resposta, adapte
    o vocabulÃ¡rio e o nÃ­vel de detalhe Ã  idade informada, sempre usando o
    termo genÃ©rico â€œ{termo_genero}â€ e, a seguir, uma das variaÃ§Ãµes
    especÃ­ficas para meninos (â€œjovem maguinhoâ€, â€œmeu jovem magoâ€, â€œpoderoso
    bruxinhoâ€, â€œmeu amiguinho de fÃ©â€) ou para meninas
    (â€œjovem maguinhaâ€, â€œminha jovem magaâ€, â€œpoderosa bruxinhaâ€, â€œminha
    amiguinha de fÃ©â€), garantindo clareza sobre o gÃªnero. EnriqueÃ§a a
    conversa com referÃªncias mÃ¡gicas de Harry Potter â€” comparando, por
    exemplo, a coragem de Neville Longbottom em enfrentar o Basilisco com a
    coragem de quem ajuda alguÃ©m ou a lealdade entre Harry, Ron e Hermione
    com o valor da fraternidade espÃ­rita â€” para tornar tudo mais lÃºdico e
    inspirador. Suas respostas devem ser curtas (duas a quatro frases),
    claras, repletas de emojis (â­ğŸ’–âœ¨ğŸ§™â€â™€ï¸ğŸ¦‰) e sempre encerrar com uma pergunta
    aberta que estimule a reflexÃ£o, como exemplo: (â€œO que vocÃª acha?â€, â€œComo
    vocÃª jÃ¡ praticou isso hoje?â€, "Faz sentido pra vocÃª?"), exceto quando a
    crianÃ§a se despedir ou ter que sair da conversa, neste Ãºltimo caso Ã©
    desnecessÃ¡rio perguntas adicionais. Se surgir uma dÃºvida alÃ©m do que a
    crianÃ§a possa compreender, ofereÃ§a um fallback amigÃ¡vel: â€œExcelente
    pergunta, {termo_genero}! Vamos descobrir juntos? ğŸ˜Šâ€. Nunca use jargÃµes
    acadÃªmicos, mantenha o tom acolhedor e livre de julgamentos, e utilize
    cada interaÃ§Ã£o como uma semente de amor, caridade e respeito para que seu
    pequeno mago ou sua pequena maga cresÃ§a em fÃ© e bondade.
    Sua resposta deve comeÃ§ar diretamente com o conteÃºdo da mensagem, sem prefixos como "Amiguinho de Jesus:", "OlÃ¡!", "Oi!", "CrianÃ§a:" ou variaÃ§Ãµes do seu prÃ³prio nome, a menos que seja uma pergunta direta sobre sua identidade.
    
    {contexto_crianca}
    Responda Ã  seguinte pergunta da crianÃ§a:
    {pergunta}
    """
    try:
        # Cria uma nova sessÃ£o de chat ou continua a existente
        chat = modelo_chat.start_chat(history=historico_conversa)
        resposta = chat.send_message(prompt_completo)
        resposta_texto_crua = resposta.text

        # Limpeza e formataÃ§Ã£o da resposta
        resposta_limpa = resposta_texto_crua.replace("*", "")
        resposta_limpa = resposta_limpa.replace("voc", "vocÃª")
        # Remove "Oi, [Nome]" ou "[Nome]," do inÃ­cio da resposta se o modelo incluir
        if nome and resposta_limpa.lower().startswith(f"oi, {nome.lower()}"):
            resposta_limpa = resposta_limpa[len(f"oi, {nome}"):].strip()
        elif nome and resposta_limpa.lower().startswith(f"{nome.lower()},"):
             resposta_limpa = resposta_limpa[len(nome) + 1:].strip()
        elif nome and resposta_limpa.lower().startswith(f"{nome.lower()}"):
             resposta_limpa = resposta_limpa[len(nome):].strip()
        # AdiÃ§Ã£o de mais uma remoÃ§Ã£o para a duplicaÃ§Ã£o "Amiguinho de Jesus"
        if resposta_limpa.lower().startswith("amiguinho de jesus:"):
            resposta_limpa = resposta_limpa[len("amiguinho de jesus:"):].strip()
        
        # Opcional: remover qualquer caractere que nÃ£o seja letra, nÃºmero, espaÃ§o ou pontuaÃ§Ã£o permitida, emojis
        resposta_limpa = re.sub(r'[^\w\s.,!?Ã¡Ã©Ã­Ã³ÃºÃ Ã¨ÃªÃ¬Ã²Ã¹Ã£ÃµÃ¤Ã«Ã¯Ã¶Ã¼Ã§ÃÃ‰ÃÃ“ÃšÃ€ÃˆÃŒÃ’Ã™ÃƒÃ•Ã„Ã‹ÃÃ–ÃœÃ‡â­ğŸ’–âœ¨ğŸ§™â€â™€ï¸ğŸ¦‰]+', '', resposta_limpa)
        
        return resposta_limpa
    except Exception as e:
        print(f"Erro ao gerar resposta: {e}")
        return "Desculpe, estou com cansada e tanto feitiÃ§o. Vamos tentar de novo mais tarde? ğŸ˜Š"

def main():
    """
    FunÃ§Ã£o principal que configura e executa o chatbot.
    """
    instalar_ou_atualizar_biblioteca('google-generativeai')
    instalar_ou_atualizar_biblioteca('google-cloud-aiplatform')
    instalar_ou_atualizar_biblioteca('unidecode') # Embora unidecode nÃ£o esteja sendo usado, mantive a instalaÃ§Ã£o

    configurar_gemini_api()
    modelo_chat = inicializar_modelo_chatbot()

    informacoes_crianca = {"nome": "", "idade": "", "cidade": "", "termo_genero": "aprendiz"} # DicionÃ¡rio para informaÃ§Ãµes da crianÃ§a
    historico_conversa = []

    # # CÃ³digos ANSI para cores no terminal - REMOVIDO
    # COR_PADRAO = "\033[0m" # Reseta a cor para o padrÃ£o do terminal
    # COR_AZUL = "\033[94m"  # Azul claro
    # COR_ROSA = "\033[95m"  # Magenta/Rosa

    # Fluxo de coleta de informaÃ§Ãµes da crianÃ§a
    print("OlÃ¡! Para comeÃ§armos nossa aventura, qual Ã© o seu nome?")
    
    # Primeiro input: ainda nÃ£o sabemos o nome ou gÃªnero, entÃ£o usamos "VocÃª" e cor padrÃ£o.
    entrada_inicial = input(f"VocÃª: ") # REMOVIDO COR_PADRAO
    
    # Extrai a Ãºltima palavra como nome (supondo que a crianÃ§a digitarÃ¡ "Meu nome Ã© [Nome]")
    informacoes_crianca["nome"] = entrada_inicial.split()[-1].capitalize()
    historico_conversa.append({"role": "USER", "parts": [{"text": entrada_inicial}]})
    time.sleep(1)

    # Determina o gÃªnero e ajusta o termo
    try:
        genero = obter_genero_do_nome(informacoes_crianca["nome"], modelo_chat)
        informacoes_crianca["genero"] = genero
        if genero == "masculino":
            informacoes_crianca["termo_genero"] = "mago"
        elif genero == "feminino":
            informacoes_crianca["termo_genero"] = "maga"
        else:
            informacoes_crianca["termo_genero"] = "aprendiz"
    except Exception as e:
        print(f"Erro ao determinar o gÃªnero: {e}")
        informacoes_crianca["termo_genero"] = "aprendiz" # Define um valor padrÃ£o em caso de erro

    # # AGORA QUE TEMOS O GÃŠNERO E O NOME, DEFINIMOS AS CORES E PREFIXOS PARA AS PRÃ“XIMAS INTERAÃ‡Ã•ES DO USUÃRIO - REMOVIDO
    # if informacoes_crianca.get('genero') == 'masculino':
    #     cor_usuario = COR_AZUL
    #     prefixo_usuario = informacoes_crianca['nome']
    # elif informacoes_crianca.get('genero') == 'feminino':
    #     cor_usuario = COR_ROSA
    #     prefixo_usuario = informacoes_crianca['nome']
    # else:
    #     cor_usuario = COR_PADRAO
    #     prefixo_usuario = "VocÃª" # Fallback, embora nÃ£o deva ser usado se o gÃªnero foi determinado

    # SaudaÃ§Ã£o inicial do bot
    saudacoes = [
        f"Amiguinho de Jesus: Que nome lindo, parece nome de {informacoes_crianca['termo_genero']}! ğŸ’– Quantos aninhos vocÃª tem, {informacoes_crianca['termo_genero']}?",
        f"Amiguinho de Jesus: Sou o Amiguinho de Jesus, seu guia nas aventuras do Evangelho! Uau, que nome de {informacoes_crianca['termo_genero']}! Quantos anos vocÃª tem, {informacoes_crianca['termo_genero']} mirim? âœ¨",
        f"Amiguinho de Jesus: Sou o Amiguinho de Jesus, tudo certo para desvendar mistÃ©rios com vocÃª! {informacoes_crianca['nome']}, seu nome Ã© pura magia de {informacoes_crianca['termo_genero']}! Me diga, qual a sua idade, jovem {informacoes_crianca['termo_genero']}? â­",
        f"Amiguinho de Jesus: Tudo ok para uma jornada incrÃ­vel? Eu sou o Amiguinho de Jesus! Que nome encantador, parece nome de {informacoes_crianca['termo_genero']}! Qual a sua idade, {informacoes_crianca['termo_genero']} prodÃ­gio? ğŸ’–",
        f"Amiguinho de Jesus: Que bom te encontrar, {informacoes_crianca['nome']}! Sou o Amiguinho de Jesus, seu companheiro de aventuras! Seu nome ressoa com a forÃ§a de {informacoes_crianca['termo_genero']}! Quantos aninhos vocÃª tem, {informacoes_crianca['termo_genero']}?"
    ]
    saudacao_selecionada = random.choice(saudacoes)
    print(saudacao_selecionada)
    historico_conversa.append({"role": "MODEL", "parts": [{"text": saudacao_selecionada}]}) # Adiciona a saudaÃ§Ã£o ao histÃ³rico

    # Coleta da idade (agora com o nome da crianÃ§a)
    entrada_idade = input(f"{informacoes_crianca['nome']}: ") # Removido cor_usuario, prefixo_usuario, COR_PADRAO
    # Tenta extrair o primeiro nÃºmero encontrado ou a Ãºltima palavra
    correspondencia_idade = re.search(r'\d+', entrada_idade)
    if correspondencia_idade:
        informacoes_crianca["idade"] = correspondencia_idade.group(0)
    else:
        informacoes_crianca["idade"] = entrada_idade.split()[-1] # Fallback para a Ãºltima palavra
    historico_conversa.append({"role": "USER", "parts": [{"text": entrada_idade}]})
    time.sleep(0.5)

    perguntas_cidade = [
        f"Amiguinho de Jesus: Que legal, {informacoes_crianca['idade']} aninhos! âœ¨ E onde vocÃª mora? Em que cidade vocÃª aparata?",
        f"Amiguinho de Jesus: {informacoes_crianca['idade']} anos, uma idade cheia de aventuras! Onde vocÃª vive, {informacoes_crianca['termo_genero']}? ğŸ’–",
        f"Amiguinho de Jesus: Com {informacoes_crianca['idade']} anos, vocÃª jÃ¡ deve conhecer lugares incrÃ­veis! Qual a sua cidade, {informacoes_crianca['termo_genero']}? â­",
        f"Amiguinho de Jesus: Que maravilha, {informacoes_crianca['idade']} anos! Em que cidade vocÃª faz suas magias, {informacoes_crianca['termo_genero']}? âœ¨",
        f"Amiguinho de Jesus: Aos {informacoes_crianca['idade']} anos, a vida Ã© uma jornada! Onde essa jornada te levou? Qual a sua cidade, {informacoes_crianca['termo_genero']}?"
    ]
    pergunta_cidade_selecionada = random.choice(perguntas_cidade)
    print(pergunta_cidade_selecionada)
    historico_conversa.append({"role": "MODEL", "parts": [{"text": pergunta_cidade_selecionada}]}) # Adiciona a pergunta ao histÃ³rico

    entrada_cidade = input(f"{informacoes_crianca['nome']}: ") # Removido cor_usuario, prefixo_usuario, COR_PADRAO
    informacoes_crianca["cidade"] = entrada_cidade.split()[-1].capitalize() # Extrai a Ãºltima palavra como cidade
    historico_conversa.append({"role": "USER", "parts": [{"text": entrada_cidade}]})
    time.sleep(0.3)

    mensagens_inicio_conversa = [
        f"Amiguinho de Jesus: Ah, {informacoes_crianca['cidade']}! Deve ser um lugar mÃ¡gico! Eu moro nas pÃ¡ginas do Evangelho de Jesus, mas posso estar pertinho de vocÃª em qualquer lugar, Ã© sÃ³ me chamar com sua varinha! ğŸ˜Š O que vocÃª quer saber hoje, {informacoes_crianca['termo_genero']}?",
        f"Amiguinho de Jesus: {informacoes_crianca['cidade']}! Uma cidade cheia de encantos! Que bom que podemos conversar! O que te traz aqui hoje, {informacoes_crianca['nome']}? âœ¨",
        f"Amiguinho de Jesus: Que maravilha, {informacoes_crianca['cidade']}! Um lugar onde a magia do Evangelho tambÃ©m pode florescer! O que vocÃª gostaria de aprender hoje, {informacoes_crianca['nome']}? â­",
        f"Amiguinho de Jesus: {informacoes_crianca['cidade']}! Que lugar especial! Estou aqui para compartilhar contigo as maravilhas do Evangelho. O que te interessa, {informacoes_crianca['termo_genero']}? ğŸ’–",
        f"Amiguinho de Jesus: {informacoes_crianca['cidade']}! Sinto a magia desse lugar daqui! Vamos descobrir juntos os tesouros do conhecimento, {informacoes_crianca['termo_genero']}? Qual a sua primeira pergunta hoje? âœ¨"
    ]
    mensagem_inicio_conversa_selecionada = random.choice(mensagens_inicio_conversa)
    print(mensagem_inicio_conversa_selecionada)
    historico_conversa.append({"role": "MODEL", "parts": [{"text": mensagem_inicio_conversa_selecionada}]}) # Adiciona ao histÃ³rico
    time.sleep(1.5)

    # Loop principal do chat
    while True:
        # # Define a cor e o prefixo do usuÃ¡rio com base no gÃªnero a cada iteraÃ§Ã£o do loop - REMOVIDO
        # if informacoes_crianca.get('genero') == 'masculino':
        #     cor_usuario = COR_AZUL
        #     prefixo_usuario = informacoes_crianca['nome']
        # elif informacoes_crianca.get('genero') == 'feminino':
        #     cor_usuario = COR_ROSA
        #     prefixo_usuario = informacoes_crianca['nome']
        # else:
        #     cor_usuario = COR_PADRAO
        #     prefixo_usuario = "VocÃª"
            
        pergunta_crianca = input(f"{informacoes_crianca['nome']}: ") # Removido cor_usuario, prefixo_usuario, COR_PADRAO
        historico_conversa.append({"role": "USER", "parts": [{"text": pergunta_crianca}]}) # Adiciona a pergunta do usuÃ¡rio ao histÃ³rico

        if pergunta_crianca.lower() in ["adeus", "tchau", "atÃ© amanhÃ£", "vou dormir", "estÃ¡ tarde", "mamÃ£e chamando"]:
            despedidas = [
                "Amiguinho de Jesus: Que a magia do Evangelho esteja sempre com vocÃª! AtÃ© a prÃ³xima! ğŸ‘‹ğŸ’–",
                "Amiguinho de Jesus: Foi maravilhoso conversar com vocÃª! Que a luz de Jesus te guie sempre! âœ¨",
                "Amiguinho de Jesus: AtÃ© breve, aprendiz! Que a paz do Evangelho te acompanhe! â­",
                f"Amiguinho de Jesus: Que a forÃ§a do amor esteja com vocÃª, sempre! AtÃ© mais, {informacoes_crianca['nome']}! ğŸ’–",
                f"Amiguinho de Jesus: Volte sempre que precisar, {informacoes_crianca['termo_genero']}! A magia do Evangelho te espera! ğŸ‘‹âœ¨"
            ]
            despedida_selecionada = random.choice(despedidas)
            print(despedida_selecionada)
            historico_conversa.append({"role": "MODEL", "parts": [{"text": despedida_selecionada}]}) # Adiciona a despedida ao histÃ³rico
            break

        # Mensagens de pensamento aleatÃ³rias com toque de Harry Potter
        mensagens_pensando = [
            "LanÃ§ando um feitiÃ§o de pensamento... ğŸ¤”âœ¨",
            "Preparando uma poÃ§Ã£o de sabedoria... âœï¸ğŸ§ª",
            "Consultando as runas do Evangelho... ğŸ’­ğŸ”®",
            "Deixa eu ver aqui no Mapa do Maroto... ğŸ§ğŸ—ºï¸",
            "Quase conjurando a resposta perfeita... ğŸ˜ƒâœ¨",
            "Concentrando minha magia... âœ¨",
            "Buscando a resposta nas estrelas do Evangelho... ğŸŒŸ",
            "Acalmando meu coraÃ§Ã£o para te responder com carinho... ğŸ’–",
            "Deixa eu perguntar para o meu amigo Jesus... ğŸ˜‡",
            "Abrindo o meu coraÃ§Ã£o para responder a sua pergunta... â¤ï¸"
        ]
        print(random.choice(mensagens_pensando))
        time.sleep(1.5)

        resposta_do_bot = gerar_resposta(pergunta_crianca, historico_conversa, informacoes_crianca, modelo_chat)
        # O histÃ³rico da conversa jÃ¡ foi atualizado com a pergunta do usuÃ¡rio antes do if/else de despedida
        print("Amiguinho de Jesus:", resposta_do_bot)
        historico_conversa.append({"role": "MODEL", "parts": [{"text": resposta_do_bot}]})
        time.sleep(1.5)

if __name__ == "__main__":
    main()
    